{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# CITATION: I heavily relied on the following source: https://towardsdatascience.com/image-detection-from-scratch-in-keras-f314872006c9'''\n\n# this code block LOADS THE DATA\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport random\nimport matplotlib.image as mpimg\n# gc cleans deleted data from memory\nimport gc\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# obtain the names of all images\ntrain_dog = os.listdir(\"../input/training_set/training_set/dogs/\")\ntrain_cat = os.listdir(\"../input/training_set/training_set/cats/\")\n\n# os.listdir doesn't list the absolute path to the image, but we need that, so:\ntrain_dog = [\"../input/training_set/training_set/dogs/\"+img for img in train_dog]\ntrain_cat = [\"../input/training_set/training_set/cats/\"+img for img in train_cat]\n\ntrain_images = train_dog[:2000] + train_cat[:2000]\nrandom.shuffle(train_images)\n\n# now we have training set, so don't need the rest of the images -- delete to save memory\ndel train_dog\ndel train_cat\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# this code block RESIZES IMAGES\n\nnum_rows = 150\nnum_columns = 150\n# channels refers to color, 1=grayscale, 3=color\nchannels = 3\n\ndef readAndProcessImages(list_of_images):\n    ''' Returns two arrays:\n        1) resized images, called \"resized_images\",\n        2) labels, called \"labels\", which consists of 1s and 0s -- label 1 means it is a dog and 0 means it is a cat '''\n    \n    resized_training_images = []\n    training_labels = []\n    \n    for image in list_of_images:\n        # read the image\n        resized = cv2.resize(cv2.imread(image,cv2.IMREAD_COLOR), (num_rows,num_columns), interpolation=cv2.INTER_CUBIC)\n        # append to list of resized images\n        resized_training_images.append(resized)\n        # get labels\n        if 'dog' in image:\n            training_labels.append(1)\n        elif 'cat' in image:\n            training_labels.append(0)\n        \n    return np.array(resized_training_images),np.array(training_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_imgs,labels = readAndProcessImages(train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_imgs[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test to make sure dogs have label 1 and cats have label 0\n# look at first five images\n\nplt.figure(figsize=(20,10))\ncolumns = 5\nfor i in range(columns):\n    plt.subplot(5/columns + 1, columns, i+1)\n    plt.imshow(training_imgs[i])\n    \nprint(labels[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confirm we have 2000 dog labels and 2000 cat labels\nsorted_labels = sorted(labels)\nprint('Here we should get 0 0')\nprint(sorted_labels[0],sorted_labels[1998])\nprint('Here we should get 0 1')\nprint(sorted_labels[1999],sorted_labels[2000])\nprint('Here we should get 1 1')\nprint(sorted_labels[2001],sorted_labels[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confirm shape of data\nprint('Shape of training set is ',training_imgs.shape)\nprint('Shape of labels is ',labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into training and test set\nfrom sklearn.model_selection import train_test_split\n# test_size=0.20 means that we will take 20% of the data for the test set and 80% goes to training\n# random_state determines whether or not you get a reproducible result -- everytime you run train_test_split you would get a different splitting of train/test images but if you specify a given integer for random_state, if you call train_test_split with that integer, then you get that same \"random\" splitting\n\n# I will call the new train/test sets 'training/test_imgs_PS' where PS stands for post-split of the original set\ntraining_imgs_PS, test_imgs_PS, label_train_PS, label_test_PS = train_test_split(training_imgs,labels,test_size=0.20,random_state=0)\n\n# check shape of new training/test sets\nprint('Shape of training set is ',training_imgs_PS.shape)\nprint('Shape of test set is ',test_imgs_PS.shape)\nprint('Shape of training labels is ',label_train_PS.shape[0])\nprint('Shape of test labels is ',label_test_PS.shape[0])\n\n# check that 20% of original set went to test set\nprint('Check that these two numbers are equal ',test_imgs_PS.shape[0],training_imgs.shape[0]*0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clear memory of pre-split img arrays\ndel training_imgs\ndel labels\ngc.collect()\n\n# obtain length of training and test data\nnum_train = len(training_imgs_PS)\nnum_test = len(test_imgs_PS)\n\n# batch size = number of samples processed before the model is updated\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model creation\n\nfrom keras import alyers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}